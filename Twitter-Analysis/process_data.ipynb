{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## PREPROCESSING DATA\n",
    "### Disaster Response Pipeline Project\n",
    "### Udacity - Data Science Nanodegree\n",
    "\n",
    "### Sample Script Execution:\n",
    "> python process_data.py data/disaster_messages.csv data/disaster_categories.csv data/DisasterResponse.db </br>\n",
    "\n",
    "Arguments:</br>\n",
    "    - CSV file containing messages (data/disaster_messages.csv)</br>\n",
    "    - CSV file containing categories (data/disaster_categories.csv)</br>\n",
    "    - SQLite destination database (data/DisasterResponse.db)</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(messages_filepath, categories_filepath):\n",
    "    \"\"\"Load and merge messages and categories datasets\n",
    "    \n",
    "    Args:\n",
    "    messages_filepath: string. Filepath for csv file containing messages dataset.\n",
    "    categories_filepath: string. Filepath for csv file containing categories dataset.\n",
    "       \n",
    "    Returns:\n",
    "    df: dataframe. Dataframe containing merged content of messages and categories datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load messages dataset\n",
    "    messages = pd.read_csv(messages_filepath)\n",
    "    \n",
    "    # Load categories dataset\n",
    "    categories = pd.read_csv(categories_filepath)\n",
    "    \n",
    "    # Merge datasets\n",
    "    df = messages.merge(categories, how = 'left', on = ['id'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"Clean dataframe by removing duplicates and converting categories from strings \n",
    "    to binary values.\n",
    "    \n",
    "    Args:\n",
    "    df: dataframe. Dataframe containing merged content of messages and categories datasets.\n",
    "       \n",
    "    Returns:\n",
    "    df: dataframe. Dataframe containing cleaned version of input dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a dataframe of the 36 individual category columns\n",
    "    categories = df['categories'].str.split(';', expand = True)\n",
    "    \n",
    "    # Select the first row of the categories dataframe\n",
    "    row = categories.iloc[0]\n",
    "\n",
    "    # use this row to extract a list of new column names for categories.\n",
    "    # one way is to apply a lambda function that takes everything \n",
    "    # up to the second to last character of each string with slicing\n",
    "    category_colnames = row.transform(lambda x: x[:-2]).tolist()\n",
    "    \n",
    "    # Rename the columns of `categories`\n",
    "    categories.columns = category_colnames\n",
    "    \n",
    "    # Convert  category values to numeric values\n",
    "    for column in categories:\n",
    "        # set each value to be the last character of the string\n",
    "        categories[column] = categories[column].transform(lambda x: x[-1:])\n",
    "        \n",
    "        # convert column from string to numeric\n",
    "        categories[column] = pd.to_numeric(categories[column])\n",
    "    \n",
    "    # Drop the original categories column from `df`\n",
    "    df.drop('categories', axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Concatenate the original dataframe with the new `categories` dataframe\n",
    "    df = pd.concat([df, categories], axis = 1)\n",
    "    \n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    \n",
    "    # Remove rows with a related value of 2 from the dataset\n",
    "    df = df[df['related'] != 2]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df, database_filename):\n",
    "    \"\"\"Save cleaned data into an SQLite database.\n",
    "    \n",
    "    Args:\n",
    "    df: dataframe. Dataframe containing cleaned version of merged message and \n",
    "    categories data.\n",
    "    database_filename: string. Filename for output database.\n",
    "       \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    #database = 'Data/'+ database_filename\n",
    "    database = database_filename\n",
    "    conn = sqlite3.connect(database)\n",
    "    df.to_sql('messages', conn, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the filepaths of the messages and categories datasets as the first and second argument respectively, as well as the filepath of the database to save the cleaned data to as the third argument. \n",
      "\n",
      "Example: python process_data.py data/messages.csv data/categories.csv data/DisasterResponse.db\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if len(sys.argv) == 4:\n",
    "\n",
    "        messages_filepath, categories_filepath, database_filepath = sys.argv[1:]\n",
    "\n",
    "        print('Loading data...\\n    MESSAGES: {}\\n    CATEGORIES: {}'\n",
    "              .format(messages_filepath, categories_filepath))\n",
    "        df = load_data(messages_filepath, categories_filepath)\n",
    "\n",
    "        print('Cleaning data...')\n",
    "        df = clean_data(df)\n",
    "        \n",
    "        print('Saving data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "        save_data(df, database_filepath)\n",
    "        \n",
    "        print('Cleaned data saved to database!')\n",
    "    \n",
    "    else:\n",
    "        print('Please provide the filepaths of the messages and categories '\\\n",
    "              'datasets as the first and second argument respectively, as '\\\n",
    "              'well as the filepath of the database to save the cleaned data '\\\n",
    "              'to as the third argument. \\n\\nExample: python process_data.py '\\\n",
    "              'data/messages.csv data/categories.csv '\\\n",
    "              'data/DisasterResponse.db')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
